
[Constraints and Hallucinations: Filling in the Details](https://www.youtube.com/watch?v=mwxknB4SgvM)  
by Gerald Jay Sussman  
given at Google sometime in 2013  

Abstract:  

Ever since I was an MIT undergraduate I have been pursuing several overlapping goals:

1. To formally understand the modeling and problem-solving strategies used by scientists and engineers.

2. To automate parts of this modeling and problem solving.

3. To devise linguistic support for expressing this how-to knowledge in a way that can be understood by a human reader as well as executed by a computer.

4. To use this computational medium to communicate how-to skills more effectively to students of science and engineering.

In pursuit of these goals I have been inspired by an idea that I gleaned from conversations with Jerry Lettvin about neurophysiology when I was an undergraduate.

I will advance the following cognitive-science hypothesis: Much of what we call intelligence is filling in details in pre-established networks of constraints. Indeed, I believe that most of the reason that humans are successful problem solvers is that we can often turn complex problems into finite networks of constraints that can be attacked with with a simple process called "propagation".

For propagation to be effective it will be important that the constraints and the data that they manipulate be finite and discrete, often "symbolic", expressions.

It will turn out that appropriately configured constraint networks can be a parallel computational architecture that can be used to track the provenance of data, explain the reasons for a belief, attribute blame for a failure, learn from mistakes, and allow a system to hold multiple locally-consistent worldviews in a globally-inconsistent "mind".
 
I will illustrate these ideas with techniques for formalizing some problem-solving strategies. It will be necessary to interweave yet separate the results of a computation and the strategy by which it is accomplished. Some deductions are strategic deductions and some are actual result deductions. To effectively represent strategies it will be necessary for propositions to be able to refer to other propositions. For example, rules will have to be able to be triggered in the case that the belief status of a proposition is unknown.

The propagation model of computation supports an appropriate infrastructure, a kind of plumbing for building such systems.
